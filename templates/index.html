<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech to Text</title>
    <!-- Tailwind CSS CDN for quick styling -->
    <script src="[https://cdn.tailwindcss.com](https://cdn.tailwindcss.com)"></script>
    <link href="[https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap](https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap)" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f0f4f8; /* Light blue-gray background */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        .container {
            background-color: #ffffff; /* White card background */
            border-radius: 1.5rem; /* More rounded corners */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1); /* Soft shadow */
            padding: 2.5rem; /* Increased padding */
            text-align: center;
            width: 100%;
            max-width: 600px;
            box-sizing: border-box;
        }
        #microphone-button {
            background-color: #4CAF50; /* Green color for mic */
            color: white;
            border: none;
            border-radius: 9999px; /* Fully rounded for a circle */
            width: 80px; /* Larger button */
            height: 80px;
            font-size: 3rem; /* Larger icon */
            cursor: pointer;
            outline: none;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 0 auto 2rem auto; /* Centered with margin at bottom */
            box-shadow: 0 5px 15px rgba(76, 175, 80, 0.4); /* Green shadow */
        }
        #microphone-button:hover {
            background-color: #45a049; /* Darker green on hover */
            transform: translateY(-2px); /* Slight lift */
            box-shadow: 0 8px 20px rgba(76, 175, 80, 0.6);
        }
        #microphone-button:active {
            background-color: #3e8e41; /* Even darker on active */
            transform: translateY(0); /* Press effect */
            box-shadow: 0 3px 10px rgba(76, 175, 80, 0.3);
        }
        #microphone-button.recording {
            background-color: #f44336; /* Red when recording */
            box-shadow: 0 5px 15px rgba(244, 67, 54, 0.4); /* Red shadow */
            animation: pulse 1.5s infinite alternate; /* Pulsing animation */
        }
        @keyframes pulse {
            0% { transform: scale(1); box-shadow: 0 5px 15px rgba(244, 67, 54, 0.4); }
            100% { transform: scale(1.05); box-shadow: 0 8px 20px rgba(244, 67, 54, 0.6); }
        }
        #transcript-output {
            background-color: #e2e8f0; /* Light gray background for text area */
            border-radius: 0.75rem;
            padding: 1.5rem;
            min-height: 100px;
            text-align: left;
            font-size: 1.125rem; /* Larger font size */
            color: #334155; /* Darker text color */
            overflow-y: auto; /* Enable scrolling for long text */
            white-space: pre-wrap; /* Preserve whitespace and wrap text */
            box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.06); /* Inner shadow for depth */
        }
        .message-box {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 20px;
            border-radius: 8px;
            z-index: 1000;
            display: none; /* Hidden by default */
            font-size: 1rem;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-3xl font-bold text-gray-800 mb-6">Speak to Me!</h1>
        <button id="microphone-button" aria-label="Start recording">
            ðŸŽ¤
        </button>
        <p class="text-gray-600 mb-4" id="status-message">Press and hold the microphone to speak.</p>
        <div id="transcript-output" class="mb-4">
            Your transcribed text will appear here.
        </div>
    </div>

    <div id="message-box" class="message-box"></div>

    <script>
        const microphoneButton = document.getElementById('microphone-button');
        const transcriptOutput = document.getElementById('transcript-output');
        const statusMessage = document.getElementById('status-message');
        const messageBox = document.getElementById('message-box');

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let audioContext;
        let scriptProcessor;
        let liveStream;

        // Function to show a temporary message box instead of alert()
        function showMessageBox(message, duration = 3000) {
            messageBox.textContent = message;
            messageBox.style.display = 'block';
            setTimeout(() => {
                messageBox.style.display = 'none';
            }, duration);
        }

        microphoneButton.addEventListener('mousedown', startRecording);
        microphoneButton.addEventListener('mouseup', stopRecording);
        // Also handle touch events for mobile devices
        microphoneButton.addEventListener('touchstart', (e) => {
            e.preventDefault(); // Prevent default touch behavior (like scrolling)
            startRecording();
        });
        microphoneButton.addEventListener('touchend', (e) => {
            e.preventDefault(); // Prevent default touch behavior
            stopRecording();
        });

        // Initialize AudioContext to ensure it's ready for recording
        // This helps in cases where browsers might require user gesture to enable AudioContext
        // We defer getUserMedia until button press
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
        }

        async function startRecording() {
            if (isRecording) return; // Prevent multiple recordings

            initAudioContext(); // Ensure AudioContext is initialized

            try {
                // Request microphone access
                liveStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(liveStream, { mimeType: 'audio/webm; codecs=opus' });
                audioChunks = []; // Clear previous chunks

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    // Create a Blob from the audio chunks
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm; codecs=opus' });
                    // Send the Blob to the Flask backend
                    await sendAudioForTranscription(audioBlob);

                    // Stop all tracks in the live stream to release microphone
                    liveStream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                microphoneButton.classList.add('recording');
                statusMessage.textContent = "Recording... Release to transcribe.";
                transcriptOutput.textContent = "Listening..."; // Clear previous text
            } catch (error) {
                console.error('Error accessing microphone:', error);
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showMessageBox('Microphone access denied. Please allow microphone access in your browser settings.');
                } else if (error.name === 'NotFoundError') {
                    showMessageBox('No microphone found. Please ensure you have a microphone connected.');
                } else {
                    showMessageBox('Error accessing microphone: ' + error.message);
                }
                statusMessage.textContent = "Failed to start recording.";
            }
        }

        function stopRecording() {
            if (!isRecording) return;

            mediaRecorder.stop();
            isRecording = false;
            microphoneButton.classList.remove('recording');
            statusMessage.textContent = "Processing audio...";
        }

        async function sendAudioForTranscription(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'audio.webm'); // 'audio.webm' is the filename

            try {
                const response = await fetch('/transcribe', {
                    method: 'POST',
                    body: formData,
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error || 'Failed to transcribe audio.');
                }

                const data = await response.json();
                if (data.transcript) {
                    transcriptOutput.textContent = data.transcript;
                    statusMessage.textContent = "Transcription complete. Press and hold to speak again.";
                } else {
                    transcriptOutput.textContent = "No speech detected or transcription failed.";
                    statusMessage.textContent = "Please try speaking again. Press and hold the microphone.";
                }
            } catch (error) {
                console.error('Error sending audio for transcription:', error);
                transcriptOutput.textContent = `Error: ${error.message}`;
                statusMessage.textContent = "Error during transcription. Please check console.";
                showMessageBox(`Transcription Error: ${error.message}`);
            }
        }
    </script>
</body>
</html>
